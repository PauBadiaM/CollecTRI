{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b678fab0-25e7-4b41-a366-fae9f041bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import decoupler as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eeef57e8-7c3a-483f-8c88-53d60b1995b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.read_csv('/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_expr.csv', index_col=0)\n",
    "obs = pd.read_csv('/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_meta.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16defaac-2070-41aa-abcc-36aaff8eda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doro_ABC = dc.get_dorothea(levels=['A', 'B', 'C'])\n",
    "regnet = pd.read_csv('../data/raw/regnetwork.csv')\n",
    "chea3 = pd.read_csv('../data/raw/chea3.csv')\n",
    "collecTRI_signed = pd.read_csv('../output/040722/02_signed_networks/strict_signed_CollecTRI.csv')\n",
    "collecTRI_agnostic = pd.read_csv('../output/040722/02_signed_networks/strict_signed_CollecTRI.csv')\n",
    "collecTRI_agnostic['weight'] = 1\n",
    "collecTRI_rand = dc.shuffle_net(collecTRI_agnostic, target='target', weight='weight').drop_duplicates(['source', 'target'])\n",
    "collecTRI_rand_signed = dc.shuffle_net(collecTRI_signed, target='target', weight='weight').drop_duplicates(['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c11ea6c8-7fda-49d0-9fd1-5f871f0697bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = obs['logFC'] < -1\n",
    "mat = mat[msk]\n",
    "obs = obs[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16c533c0-968a-4085-b167-63be37f43d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZHX3', 'TCF7L1'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corr_regnet = dc.check_corr(net=regnet, mat=mat)\n",
    "#corr_tfs = corr_regnet['source2'][corr_regnet['corr'] >= 1].values\n",
    "\n",
    "#regnet_filtered = regnet.loc[~regnet['source'].isin(corr_tfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6755289-79fb-44b1-8115-7fdafe51c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decouple_kws =  {'source': 'source', 'target': 'target', 'weight': 'weight', 'min_n': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "193ed24e-bedf-4a8b-97b0-89e044b7fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_regnet, obs_regnet, var_regnet, regnet, groupby_regnet = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = regnet, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)\n",
    "mat_doro_ABC, obs_doro_ABC, var_doro_ABC, doro_ABC, groupby_doro_ABC = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = doro_ABC, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)\n",
    "mat_collecTRI_signed, obs_collecTRI_signed, var_collecTRI_signed, collecTRI_signed, groupby_collecTRI_signed = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = collecTRI_signed, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)\n",
    "mat_collecTRI_agnostic, obs_collecTRI_agnostic, var_collecTRI_agnostic, collecTRI_agnostic, groupby_collecTRI_agnostic = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = collecTRI_agnostic, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f86b1ed-73ea-4233-b965-a571512251ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_regnet_new = pd.DataFrame(mat_regnet.A, index=obs_regnet.index, columns=var_regnet.index)\n",
    "mat_doro_ABC_new = pd.DataFrame(mat_doro_ABC.A, index=obs_doro_ABC.index, columns=var_doro_ABC.index)\n",
    "mat_collecTRI_signed_new = pd.DataFrame(mat_collecTRI_signed.A, index=obs_collecTRI_signed.index, columns=var_collecTRI_signed.index)\n",
    "mat_collecTRI_agnostic_new = pd.DataFrame(mat_collecTRI_agnostic.A, index=obs_collecTRI_agnostic.index, columns=var_collecTRI_agnostic.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14def747-3f05-42a2-9e5f-bf5b088314c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 207 samples and 21930 targets for 434 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 207 samples and 21930 targets for 434 sources.\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 207 samples and 21930 targets for 434 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:39<00:00, 39.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 214 samples and 21930 targets for 297 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 214 samples and 21930 targets for 297 sources.\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 214 samples and 21930 targets for 297 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:30<00:00, 30.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 266 samples and 21933 targets for 702 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 266 samples and 21933 targets for 702 sources.\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 266 samples and 21933 targets for 702 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:04<00:00, 64.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 266 samples and 21933 targets for 702 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 266 samples and 21933 targets for 702 sources.\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 266 samples and 21933 targets for 702 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:04<00:00, 64.13s/it]\n"
     ]
    }
   ],
   "source": [
    "results_regnet = dc.decouple(mat_regnet_new, net=regnet, source='source', target='target', weight='weight', verbose=True, min_n=5)\n",
    "results_doro = dc.decouple(mat_doro_ABC_new, net=doro_ABC, source='source', target='target', weight='weight', verbose=True, min_n=5)\n",
    "results_collecTRI_signed = dc.decouple(mat_collecTRI_signed_new, net=collecTRI_signed, source='source', target='target', weight='weight', verbose=True, min_n=5)\n",
    "results_collecTRI_agnostic = dc.decouple(mat_collecTRI_agnostic_new, net=collecTRI_agnostic, source='source', target='target', weight='weight', verbose=True, min_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76209db4-d5c2-421b-b680-e199d0554e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "chea3_archs4 = chea3[chea3['confidence'] == 'ARCHS4_Coexpression']\n",
    "chea3_encode = chea3[chea3['confidence'] == 'ENCODE_ChIP-seq']\n",
    "chea3_enrich = chea3[chea3['confidence'] == 'Enrichr_Queries']\n",
    "chea3_GTEx = chea3[chea3['confidence'] == 'GTEx_Coexpression']\n",
    "chea3_lit = chea3[chea3['confidence'] == 'Literature_ChIP-seq']\n",
    "chea3_remap = chea3[chea3['confidence'] == 'ReMap_ChIP-seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f988c1b-6a84-4980-8a78-16345bef0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(results_regnet['consensus_estimate'], '../output/040722/decoupler/regnet_consensus.csv')\n",
    "pd.DataFrame.to_csv(results_doro['consensus_estimate'], '../output/040722/decoupler/doro_consensus.csv')\n",
    "pd.DataFrame.to_csv(results_collecTRI_signed['consensus_estimate'], '../output/040722/decoupler/collecTRI_signed_consensus.csv')\n",
    "pd.DataFrame.to_csv(results_collecTRI_agnostic['consensus_estimate'], '../output/040722/decoupler/collecTRI_agnostic_consensus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e201b8dd-8091-412e-90c5-3cf9b38e3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_signed_weighted_res = results_signed_weighted_res['consensus_estimate']\n",
    "consensus_agnostic_res = results_agnostic_res['consensus_estimate']\n",
    "consensus_signed_res = results_signed_res['consensus_estimate']\n",
    "consensus_weighted_res = results_weighted_res['consensus_estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1966fdbf-c23f-4722-827f-9bc6c441ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(consensus_collectri, '../output/consensus_collectri.csv')\n",
    "pd.DataFrame.to_csv(consensus_doro, '../output/consensus_doro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2987fedd-3562-4c30-925e-6a49d22b47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(results_signed_weighted_res[0], '../output/040722/decoupler/mean_signed_weighted_res.csv')\n",
    "pd.DataFrame.to_csv(results_agnostic_res[0], '../output/040722/decoupler/mean_agnostic_res.csv')\n",
    "pd.DataFrame.to_csv(results_signed_res[0], '../output/040722/decoupler/mean_signed_res.csv')\n",
    "pd.DataFrame.to_csv(results_weighted_res[0], '../output/040722/decoupler/mean_weighted_res.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoupler",
   "language": "python",
   "name": "decoupler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
