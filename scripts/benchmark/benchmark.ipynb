{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ff99f3-5920-4c4c-a6bf-14c5ec5c7ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import decoupler as dc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69878375-b2f9-401c-9273-cbd2c6de0dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "print(dc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6fec412-c505-4e48-9d81-9bb0e6f12d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-04 11:48:29--  https://zenodo.org/record/7035528/files/knockTF_expr.csv?download=1\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 146086808 (139M) [text/plain]\n",
      "Saving to: ‘/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_expr.csv’\n",
      "\n",
      "/Users/smuellerdott 100%[===================>] 139,32M  28,0MB/s    in 5,7s    \n",
      "\n",
      "2022-10-04 11:48:35 (24,4 MB/s) - ‘/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_expr.csv’ saved [146086808/146086808]\n",
      "\n",
      "--2022-10-04 11:48:36--  https://zenodo.org/record/7035528/files/knockTF_meta.csv?download=1\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 144861 (141K) [text/plain]\n",
      "Saving to: ‘/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_meta.csv’\n",
      "\n",
      "/Users/smuellerdott 100%[===================>] 141,47K  --.-KB/s    in 0,05s   \n",
      "\n",
      "2022-10-04 11:48:36 (2,76 MB/s) - ‘/Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_meta.csv’ saved [144861/144861]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://zenodo.org/record/7035528/files/knockTF_expr.csv?download=1' -O /Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_expr.csv\n",
    "!wget 'https://zenodo.org/record/7035528/files/knockTF_meta.csv?download=1' -O /Users/smuellerdott/Documents/NTNUdecoupleR/data/knockTF_meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5146554-d8ea-42ce-88c6-dcdc92f60ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.read_csv('../../data/knockTF_expr.csv', index_col=0)\n",
    "obs = pd.read_csv('../../data/knockTF_meta.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f40e67b-b84c-4326-bd8b-b1514dc6356b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388, 21985), (388, 13), (234,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = obs['logFC'] < -1\n",
    "mat = mat[msk]\n",
    "obs = obs[msk]\n",
    "mat.shape, obs.shape, pd.unique(obs['TF'].values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c01008-6929-40f7-b45f-39ba70295cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doro_ABC = pd.read_csv('../../data/networks/filtered_dorothea_ABC.csv')\n",
    "regnet = pd.read_csv('../../data/networks/filtered_regnetwork.csv')\n",
    "pathComp = pd.read_csv('../../data/networks/filtered_pathwayCommons.csv')\n",
    "chea3 = pd.read_csv('../../data/networks/filtered_chea3.csv')\n",
    "collecTRI = pd.read_csv('../../output/CollecTRI/CollecTRI.csv')\n",
    "collecTRI_rand = dc.shuffle_net(collecTRI, target='target', weight='weight').drop_duplicates(['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b97d7c6-6f9b-4776-9230-9c0f7fc6737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chea3_archs4 = chea3[chea3['confidence'] == 'ARCHS4_Coexpression']\n",
    "chea3_encode = chea3[chea3['confidence'] == 'ENCODE_ChIP-seq']\n",
    "chea3_enrich = chea3[chea3['confidence'] == 'Enrichr_Queries']\n",
    "chea3_GTEx = chea3[chea3['confidence'] == 'GTEx_Coexpression']\n",
    "chea3_lit = chea3[chea3['confidence'] == 'Literature_ChIP-seq']\n",
    "chea3_remap = chea3[chea3['confidence'] == 'ReMap_ChIP-seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbe2f94-f973-4a82-b38c-1a06c595a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated sources from pathComp\n",
    "decouple_kws =  {'source': 'source', 'target': 'target', 'weight': 'weight', 'min_n': 5}\n",
    "mat_pathComp, obs_pathComp, var_pathComp, pathComp, groupby_pathComp = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = pathComp, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)\n",
    "\n",
    "corr_res = dc.check_corr(pathComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d317af8b-779f-4d23-a36d-bbc952bebac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_corr = corr_res['corr'] >= 0.95\n",
    "corr_tfs = corr_res[idx_corr]\n",
    "\n",
    "idx_tfs = np.isin(corr_tfs['source2'].values, obs['TF'].values)\n",
    "tfs_to_remove1 = corr_tfs[idx_tfs]['source1']\n",
    "tfs_to_remove2 = corr_tfs[~idx_tfs]['source2']\n",
    "\n",
    "tfs_to_remove = pd.concat([tfs_to_remove1, tfs_to_remove2])\n",
    "\n",
    "np.sum(np.isin(tfs_to_remove.values, obs['TF'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98acb7fb-0ae8-4368-8052-2ffc52c36609",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_remove = np.isin(pathComp['source'].values, tfs_to_remove.values)\n",
    "pathComp_filtered = pathComp.loc[~idx_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46a408a-1cc2-40ff-85ed-18e506543ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated sources from regnet\n",
    "decouple_kws =  {'source': 'source', 'target': 'target', 'weight': 'weight', 'min_n': 5}\n",
    "mat_regnet, obs_regnet, var_regnet, regnet, groupby_regnet = dc.format_benchmark_inputs(mat = mat, obs = obs, sign = -1, net = regnet, by = 'experiment', perturb='TF', groupby = None, decouple_kws=decouple_kws)\n",
    "\n",
    "corr_res = dc.check_corr(regnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41de332e-0a7a-4a6c-8199-633d769bfcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_corr = corr_res['corr'] >= 0.95\n",
    "corr_tfs = corr_res[idx_corr]\n",
    "\n",
    "idx_tfs = np.isin(corr_tfs['source2'].values, obs['TF'].values)\n",
    "tfs_to_remove1 = corr_tfs[idx_tfs]['source1']\n",
    "tfs_to_remove2 = corr_tfs[~idx_tfs]['source2']\n",
    "\n",
    "tfs_to_remove = pd.concat([tfs_to_remove1, tfs_to_remove2])\n",
    "\n",
    "np.sum(np.isin(tfs_to_remove.values, obs['TF'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11e5a53-d91f-4aa9-aae4-6e8e85c7563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_remove = np.isin(regnet['source'].values, tfs_to_remove.values)\n",
    "regnet_filtered = regnet.loc[~idx_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1e9d2b-5282-47d6-b4ec-1c28e298aa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 171, 123, 92, 156, 46, 146, 155, 66, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of TFs included in each network\n",
    "n_doro = np.sum(np.isin(pd.unique(doro_ABC['source'].values), pd.unique(obs['TF'].values))) \n",
    "n_collectri = np.sum(np.isin(pd.unique(collecTRI['source'].values), pd.unique(obs['TF'].values)))\n",
    "n_regnet = np.sum(np.isin(pd.unique(regnet_filtered['source'].values), pd.unique(obs['TF'].values))) \n",
    "n_pathComp = np.sum(np.isin(pd.unique(pathComp_filtered['source'].values), pd.unique(obs['TF'].values)))\n",
    "n_cheaArch = np.sum(np.isin(pd.unique(chea3_archs4['source'].values), pd.unique(obs['TF'].values))) \n",
    "n_cheaEncode = np.sum(np.isin(pd.unique(chea3_encode['source'].values), pd.unique(obs['TF'].values)))\n",
    "n_cheaEnrich = np.sum(np.isin(pd.unique(chea3_enrich['source'].values), pd.unique(obs['TF'].values))) \n",
    "n_cheaGTEx = np.sum(np.isin(pd.unique(chea3_GTEx['source'].values), pd.unique(obs['TF'].values)))\n",
    "n_chealit = np.sum(np.isin(pd.unique(chea3_lit['source'].values), pd.unique(obs['TF'].values))) \n",
    "n_cheaRemap = np.sum(np.isin(pd.unique(chea3_remap['source'].values), pd.unique(obs['TF'].values)))\n",
    "n_doro, n_collectri, n_regnet, n_pathComp, n_cheaArch, n_cheaEncode, n_cheaEnrich, n_cheaGTEx, n_chealit, n_cheaRemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d4b650-0e81-48a6-acb3-127d0fe9833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ABC network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "174 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 214 samples and 21930 targets for 297 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 214 samples and 21930 targets for 297 sources.\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 214 samples and 21930 targets for 297 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using collecTRI network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "109 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 279 samples and 21933 targets for 774 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 279 samples and 21933 targets for 774 sources.\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 279 samples and 21933 targets for 774 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:08<00:00, 68.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using regnet network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "159 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "54 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 229 samples and 21931 targets for 622 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 229 samples and 21931 targets for 622 sources.\n",
      "54 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 229 samples and 21931 targets for 622 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:52<00:00, 52.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using pathComp network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "205 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "76 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 183 samples and 21909 targets for 313 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 183 samples and 21909 targets for 313 sources.\n",
      "76 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 183 samples and 21909 targets for 313 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_archs4 network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "112 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 276 samples and 21935 targets for 1612 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 276 samples and 21935 targets for 1612 sources.\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 276 samples and 21935 targets for 1612 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [02:15<00:00, 135.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_encode network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "281 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "68 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 107 samples and 21917 targets for 133 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 107 samples and 21917 targets for 133 sources.\n",
      "68 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 107 samples and 21917 targets for 133 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:10<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_enrich network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "126 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 262 samples and 21935 targets for 1393 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 262 samples and 21935 targets for 1393 sources.\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 262 samples and 21935 targets for 1393 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [01:52<00:00, 112.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_GTEx network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "113 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 275 samples and 21935 targets for 1578 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 275 samples and 21935 targets for 1578 sources.\n",
      "50 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 275 samples and 21935 targets for 1578 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [02:12<00:00, 132.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_lit network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "224 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "68 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 164 samples and 21917 targets for 166 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 164 samples and 21917 targets for 166 sources.\n",
      "68 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 164 samples and 21917 targets for 166 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:15<00:00, 15.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using chea3_remap network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "187 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 201 samples and 21930 targets for 306 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 201 samples and 21930 targets for 306 sources.\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 201 samples and 21930 targets for 306 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using rand network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "109 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 279 samples and 21933 targets for 775 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 279 samples and 21933 targets for 775 sources.\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 279 samples and 21933 targets for 775 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:08<00:00, 68.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Build dictionary of networks to test\n",
    "nets = {\n",
    "    'ABC': doro_ABC,\n",
    "    'collecTRI': collecTRI,\n",
    "    'regnet': regnet_filtered,\n",
    "    'pathComp': pathComp_filtered,\n",
    "    'chea3_archs4': chea3_archs4,\n",
    "    'chea3_encode': chea3_encode,\n",
    "    'chea3_enrich': chea3_enrich,\n",
    "    'chea3_GTEx': chea3_GTEx,\n",
    "    'chea3_lit': chea3_lit,\n",
    "    'chea3_remap': chea3_remap,\n",
    "    'rand': collecTRI_rand\n",
    "}\n",
    "\n",
    "# Example extra arguments\n",
    "decouple_kws = {\n",
    "    'ABC': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'collecTRI': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'regnet': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'pathComp': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_archs4': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_encode': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_enrich': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_GTEx': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_lit': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'chea3_remap': {'args' : {'wsum' : {'times': 1000}}},\n",
    "    'rand': {'args' : {'wsum' : {'times': 1000}}}\n",
    "\n",
    "}\n",
    "\n",
    "# Run benchmark pipeline\n",
    "df = dc.benchmark(mat, obs, nets, perturb='TF', sign=-1, verbose=True, decouple_kws=decouple_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f8cf50-ba12-45f4-a7e9-2c8eb5382447",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, '../../output/benchmark/benchmark_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35fd957-f0d4-48e4-b181-b940173416fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ABC network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "174 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 214 samples and 21930 targets for 297 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 214 samples and 21930 targets for 297 sources.\n",
      "55 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 214 samples and 21930 targets for 297 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using regnet network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "159 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "54 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 229 samples and 21931 targets for 622 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 229 samples and 21931 targets for 622 sources.\n",
      "54 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 229 samples and 21931 targets for 622 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n",
      "Using collecTRI network...\n",
      "Extracting inputs...\n",
      "Formating net...\n",
      "109 experiments without sources in net, they will be removed.\n",
      "Running methods...\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running mlm on mat with 279 samples and 21933 targets for 774 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 279 samples and 21933 targets for 774 sources.\n",
      "52 features of mat are empty, they will be removed.\n",
      "Running wsum on mat with 279 samples and 21933 targets for 774 sources.\n",
      "Infering activities on 1 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Computing metrics...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "nets = {\n",
    "    'ABC': doro_ABC,\n",
    "    'regnet': regnet_filtered,\n",
    "    'collecTRI': collecTRI\n",
    "}\n",
    "\n",
    "# Example extra arguments\n",
    "decouple_kws = {\n",
    "    'ABC': {'args' : {'wsum' : {'times': 100}}},\n",
    "    'regnet': {'args' : {'wsum' : {'times': 100}}},\n",
    "    'collecTRI': {'args' : {'wsum' : {'times': 100}}}\n",
    "}\n",
    "\n",
    "# Run benchmark pipeline\n",
    "df_source = dc.benchmark(mat, obs, nets, perturb='TF', sign=-1, by='source', verbose=True, decouple_kws=decouple_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484e460c-e654-4566-b216-9fee335e9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df_source, '../../output/benchmark/benchmark_source_res.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoupler",
   "language": "python",
   "name": "decoupler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
